// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dialogflow/v2beta1/session.proto

// This CPP symbol can be defined to use imports that match up to the framework
// imports needed when using CocoaPods.
#if !defined(GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS)
 #define GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS 0
#endif

#if GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS
 #import <protobuf/GPBProtocolBuffers.h>
#else
 #import "GPBProtocolBuffers.h"
#endif

#if GOOGLE_PROTOBUF_OBJC_VERSION < 30002
#error This file was generated by a newer version of protoc which is incompatible with your Protocol Buffer library sources.
#endif
#if 30002 < GOOGLE_PROTOBUF_OBJC_MIN_SUPPORTED_VERSION
#error This file was generated by an older version of protoc which is incompatible with your Protocol Buffer library sources.
#endif

// @@protoc_insertion_point(imports)

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wdeprecated-declarations"

CF_EXTERN_C_BEGIN

@class DFContext;
@class DFEventInput;
@class DFInputAudioConfig;
@class DFIntent;
@class DFIntent_Message;
@class DFKnowledgeAnswers;
@class DFKnowledgeAnswers_Answer;
@class DFOutputAudioConfig;
@class DFQueryInput;
@class DFQueryParameters;
@class DFQueryResult;
@class DFSentiment;
@class DFSentimentAnalysisRequestConfig;
@class DFSentimentAnalysisResult;
@class DFSessionEntityType;
@class DFStreamingRecognitionResult;
@class DFTextInput;
@class GPBStruct;
@class GTPLatLng;
@class Status;

NS_ASSUME_NONNULL_BEGIN

#pragma mark - Enum DFAudioEncoding

/**
 * Audio encoding of the audio content sent in the conversational query request.
 * Refer to the
 * [Cloud Speech API
 * documentation](https://cloud.google.com/speech-to-text/docs/basics) for more
 * details.
 **/
typedef GPB_ENUM(DFAudioEncoding) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  DFAudioEncoding_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Not specified. */
  DFAudioEncoding_AudioEncodingUnspecified = 0,

  /** Uncompressed 16-bit signed little-endian samples (Linear PCM). */
  DFAudioEncoding_AudioEncodingLinear16 = 1,

  /**
   * [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
   * Codec) is the recommended encoding because it is lossless (therefore
   * recognition is not compromised) and requires only about half the
   * bandwidth of `LINEAR16`. `FLAC` stream encoding supports 16-bit and
   * 24-bit samples, however, not all fields in `STREAMINFO` are supported.
   **/
  DFAudioEncoding_AudioEncodingFlac = 2,

  /** 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law. */
  DFAudioEncoding_AudioEncodingMulaw = 3,

  /** Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000. */
  DFAudioEncoding_AudioEncodingAmr = 4,

  /** Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000. */
  DFAudioEncoding_AudioEncodingAmrWb = 5,

  /**
   * Opus encoded audio frames in Ogg container
   * ([OggOpus](https://wiki.xiph.org/OggOpus)).
   * `sample_rate_hertz` must be 16000.
   **/
  DFAudioEncoding_AudioEncodingOggOpus = 6,

  /**
   * Although the use of lossy encodings is not recommended, if a very low
   * bitrate encoding is required, `OGG_OPUS` is highly preferred over
   * Speex encoding. The [Speex](https://speex.org/) encoding supported by
   * Dialogflow API has a header byte in each block, as in MIME type
   * `audio/x-speex-with-header-byte`.
   * It is a variant of the RTP Speex encoding defined in
   * [RFC 5574](https://tools.ietf.org/html/rfc5574).
   * The stream is a sequence of blocks, one block per RTP packet. Each block
   * starts with a byte containing the length of the block, in bytes, followed
   * by one or more frames of Speex data, padded to an integral number of
   * bytes (octets) as specified in RFC 5574. In other words, each RTP header
   * is replaced with a single byte containing the block length. Only Speex
   * wideband is supported. `sample_rate_hertz` must be 16000.
   **/
  DFAudioEncoding_AudioEncodingSpeexWithHeaderByte = 7,
};

GPBEnumDescriptor *DFAudioEncoding_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL DFAudioEncoding_IsValidValue(int32_t value);

#pragma mark - Enum DFKnowledgeAnswers_Answer_MatchConfidenceLevel

/**
 * Represents the system's confidence that this knowledge answer is a good
 * match for this conversational query.
 **/
typedef GPB_ENUM(DFKnowledgeAnswers_Answer_MatchConfidenceLevel) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  DFKnowledgeAnswers_Answer_MatchConfidenceLevel_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Not specified. */
  DFKnowledgeAnswers_Answer_MatchConfidenceLevel_MatchConfidenceLevelUnspecified = 0,

  /** Indicates that the confidence is low. */
  DFKnowledgeAnswers_Answer_MatchConfidenceLevel_Low = 1,

  /** Indicates our confidence is medium. */
  DFKnowledgeAnswers_Answer_MatchConfidenceLevel_Medium = 2,

  /** Indicates our confidence is high. */
  DFKnowledgeAnswers_Answer_MatchConfidenceLevel_High = 3,
};

GPBEnumDescriptor *DFKnowledgeAnswers_Answer_MatchConfidenceLevel_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL DFKnowledgeAnswers_Answer_MatchConfidenceLevel_IsValidValue(int32_t value);

#pragma mark - Enum DFStreamingRecognitionResult_MessageType

/** Type of the response message. */
typedef GPB_ENUM(DFStreamingRecognitionResult_MessageType) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  DFStreamingRecognitionResult_MessageType_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Not specified. Should never be used. */
  DFStreamingRecognitionResult_MessageType_MessageTypeUnspecified = 0,

  /** Message contains a (possibly partial) transcript. */
  DFStreamingRecognitionResult_MessageType_Transcript = 1,

  /**
   * Event indicates that the server has detected the end of the user's speech
   * utterance and expects no additional speech. Therefore, the server will
   * not process additional audio (although it may subsequently return
   * additional results). The client should stop sending additional audio
   * data, half-close the gRPC connection, and wait for any additional results
   * until the server closes the gRPC connection. This message is only sent if
   * `single_utterance` was set to `true`, and is not used otherwise.
   **/
  DFStreamingRecognitionResult_MessageType_EndOfSingleUtterance = 2,
};

GPBEnumDescriptor *DFStreamingRecognitionResult_MessageType_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL DFStreamingRecognitionResult_MessageType_IsValidValue(int32_t value);

#pragma mark - DFSessionRoot

/**
 * Exposes the extension registry for this file.
 *
 * The base class provides:
 * @code
 *   + (GPBExtensionRegistry *)extensionRegistry;
 * @endcode
 * which is a @c GPBExtensionRegistry that includes all the extensions defined by
 * this file and all files that it depends on.
 **/
@interface DFSessionRoot : GPBRootObject
@end

#pragma mark - DFDetectIntentRequest

typedef GPB_ENUM(DFDetectIntentRequest_FieldNumber) {
  DFDetectIntentRequest_FieldNumber_Session = 1,
  DFDetectIntentRequest_FieldNumber_QueryParams = 2,
  DFDetectIntentRequest_FieldNumber_QueryInput = 3,
  DFDetectIntentRequest_FieldNumber_OutputAudioConfig = 4,
  DFDetectIntentRequest_FieldNumber_InputAudio = 5,
};

/**
 * The request to detect user's intent.
 **/
@interface DFDetectIntentRequest : GPBMessage

/**
 * Required. The name of the session this query is sent to. Format:
 * `projects/<Project ID>/agent/sessions/<Session ID>`, or
 * `projects/<Project ID>/agent/environments/<Environment ID>/users/<User
 * ID>/sessions/<Session ID>`. If `Environment ID` is not specified, we assume
 * default 'draft' environment. If `User ID` is not specified, we are using
 * "-". It’s up to the API caller to choose an appropriate `Session ID` and
 * `User Id`. They can be a random numbers or some type of user and session
 * identifiers (preferably hashed). The length of the `Session ID` and
 * `User ID` must not exceed 36 characters.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *session;

/** Optional. The parameters of this query. */
@property(nonatomic, readwrite, strong, null_resettable) DFQueryParameters *queryParams;
/** Test to see if @c queryParams has been set. */
@property(nonatomic, readwrite) BOOL hasQueryParams;

/**
 * Required. The input specification. It can be set to:
 *
 * 1.  an audio config
 *     which instructs the speech recognizer how to process the speech audio,
 *
 * 2.  a conversational query in the form of text, or
 *
 * 3.  an event that specifies which intent to trigger.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFQueryInput *queryInput;
/** Test to see if @c queryInput has been set. */
@property(nonatomic, readwrite) BOOL hasQueryInput;

/**
 * Optional. Instructs the speech synthesizer how to generate the output
 * audio. If this field is not set and agent-level speech synthesizer is not
 * configured, no output audio is generated.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFOutputAudioConfig *outputAudioConfig;
/** Test to see if @c outputAudioConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputAudioConfig;

/**
 * Optional. The natural language speech audio to be processed. This field
 * should be populated iff `query_input` is set to an input audio config.
 * A single request can contain up to 1 minute of speech audio data.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSData *inputAudio;

@end

#pragma mark - DFDetectIntentResponse

typedef GPB_ENUM(DFDetectIntentResponse_FieldNumber) {
  DFDetectIntentResponse_FieldNumber_ResponseId = 1,
  DFDetectIntentResponse_FieldNumber_QueryResult = 2,
  DFDetectIntentResponse_FieldNumber_WebhookStatus = 3,
  DFDetectIntentResponse_FieldNumber_OutputAudio = 4,
  DFDetectIntentResponse_FieldNumber_AlternativeQueryResultsArray = 5,
  DFDetectIntentResponse_FieldNumber_OutputAudioConfig = 6,
};

/**
 * The message returned from the DetectIntent method.
 **/
@interface DFDetectIntentResponse : GPBMessage

/**
 * The unique identifier of the response. It can be used to
 * locate a response in the training example set or for reporting issues.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *responseId;

/**
 * The selected results of the conversational query or event processing.
 * See `alternative_query_results` for additional potential results.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFQueryResult *queryResult;
/** Test to see if @c queryResult has been set. */
@property(nonatomic, readwrite) BOOL hasQueryResult;

/**
 * If Knowledge Connectors are enabled, there could be more than one result
 * returned for a given query or event and this field will contain all results
 * except for the top one which is captured in query_result. The alternative
 * results are ordered by decreasing
 * `QueryResult.intent_detection_confidence`. If Knowledge Connectors are
 * disabled this field will be empty  at which point those additional results
 * will be surfaced here.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFQueryResult*> *alternativeQueryResultsArray;
/** The number of items in @c alternativeQueryResultsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger alternativeQueryResultsArray_Count;

/**
 * Specifies the status of the webhook request. `webhook_status`
 * is never populated in webhook requests.
 **/
@property(nonatomic, readwrite, strong, null_resettable) Status *webhookStatus;
/** Test to see if @c webhookStatus has been set. */
@property(nonatomic, readwrite) BOOL hasWebhookStatus;

/** The audio data bytes encoded as specified in the request. */
@property(nonatomic, readwrite, copy, null_resettable) NSData *outputAudio;

/**
 * Instructs the speech synthesizer how to generate the output audio. This
 * field is populated from the agent-level speech synthesizer configuration,
 * if enabled.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFOutputAudioConfig *outputAudioConfig;
/** Test to see if @c outputAudioConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputAudioConfig;

@end

#pragma mark - DFQueryParameters

typedef GPB_ENUM(DFQueryParameters_FieldNumber) {
  DFQueryParameters_FieldNumber_TimeZone = 1,
  DFQueryParameters_FieldNumber_GeoLocation = 2,
  DFQueryParameters_FieldNumber_ContextsArray = 3,
  DFQueryParameters_FieldNumber_ResetContexts = 4,
  DFQueryParameters_FieldNumber_SessionEntityTypesArray = 5,
  DFQueryParameters_FieldNumber_Payload = 6,
  DFQueryParameters_FieldNumber_SentimentAnalysisRequestConfig = 10,
  DFQueryParameters_FieldNumber_KnowledgeBaseNamesArray = 12,
};

/**
 * Represents the parameters of the conversational query.
 **/
@interface DFQueryParameters : GPBMessage

/**
 * Optional. The time zone of this conversational query from the
 * [time zone database](https://www.iana.org/time-zones), e.g.,
 * America/New_York, Europe/Paris. If not provided, the time zone specified in
 * agent settings is used.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *timeZone;

/** Optional. The geo location of this conversational query. */
@property(nonatomic, readwrite, strong, null_resettable) GTPLatLng *geoLocation;
/** Test to see if @c geoLocation has been set. */
@property(nonatomic, readwrite) BOOL hasGeoLocation;

/**
 * Optional. The collection of contexts to be activated before this query is
 * executed.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFContext*> *contextsArray;
/** The number of items in @c contextsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger contextsArray_Count;

/**
 * Optional. Specifies whether to delete all contexts in the current session
 * before the new ones are activated.
 **/
@property(nonatomic, readwrite) BOOL resetContexts;

/**
 * Optional. The collection of session entity types to replace or extend
 * developer entities with for this query only. The entity synonyms apply
 * to all languages.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFSessionEntityType*> *sessionEntityTypesArray;
/** The number of items in @c sessionEntityTypesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger sessionEntityTypesArray_Count;

/**
 * Optional. This field can be used to pass custom data into the webhook
 * associated with the agent. Arbitrary JSON objects are supported.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GPBStruct *payload;
/** Test to see if @c payload has been set. */
@property(nonatomic, readwrite) BOOL hasPayload;

/**
 * Optional. KnowledgeBases to get alternative results from. If not set, the
 * KnowledgeBases enabled in the agent (through UI) will be used.
 * Format:  `projects/<Project ID>/knowledgeBases/<Knowledge Base ID>`.
 *
 * Note: This field is `repeated` for forward compatibility, currently only
 * the first one is supported, we may return an error if multiple
 * KnowledgeBases are specified.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<NSString*> *knowledgeBaseNamesArray;
/** The number of items in @c knowledgeBaseNamesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger knowledgeBaseNamesArray_Count;

/**
 * Optional. Configures the type of sentiment analysis to perform. If not
 * provided, sentiment analysis is not performed.
 * Note: Sentiment Analysis is only currently available for Enterprise Edition
 * agents.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFSentimentAnalysisRequestConfig *sentimentAnalysisRequestConfig;
/** Test to see if @c sentimentAnalysisRequestConfig has been set. */
@property(nonatomic, readwrite) BOOL hasSentimentAnalysisRequestConfig;

@end

#pragma mark - DFQueryInput

typedef GPB_ENUM(DFQueryInput_FieldNumber) {
  DFQueryInput_FieldNumber_AudioConfig = 1,
  DFQueryInput_FieldNumber_Text = 2,
  DFQueryInput_FieldNumber_Event = 3,
};

typedef GPB_ENUM(DFQueryInput_Input_OneOfCase) {
  DFQueryInput_Input_OneOfCase_GPBUnsetOneOfCase = 0,
  DFQueryInput_Input_OneOfCase_AudioConfig = 1,
  DFQueryInput_Input_OneOfCase_Text = 2,
  DFQueryInput_Input_OneOfCase_Event = 3,
};

/**
 * Represents the query input. It can contain either:
 *
 * 1.  An audio config which
 *     instructs the speech recognizer how to process the speech audio.
 *
 * 2.  A conversational query in the form of text,.
 *
 * 3.  An event that specifies which intent to trigger.
 **/
@interface DFQueryInput : GPBMessage

/** Required. The input specification. */
@property(nonatomic, readonly) DFQueryInput_Input_OneOfCase inputOneOfCase;

/** Instructs the speech recognizer how to process the speech audio. */
@property(nonatomic, readwrite, strong, null_resettable) DFInputAudioConfig *audioConfig;

/** The natural language text to be processed. */
@property(nonatomic, readwrite, strong, null_resettable) DFTextInput *text;

/** The event to be processed. */
@property(nonatomic, readwrite, strong, null_resettable) DFEventInput *event;

@end

/**
 * Clears whatever value was set for the oneof 'input'.
 **/
void DFQueryInput_ClearInputOneOfCase(DFQueryInput *message);

#pragma mark - DFQueryResult

typedef GPB_ENUM(DFQueryResult_FieldNumber) {
  DFQueryResult_FieldNumber_QueryText = 1,
  DFQueryResult_FieldNumber_SpeechRecognitionConfidence = 2,
  DFQueryResult_FieldNumber_Action = 3,
  DFQueryResult_FieldNumber_Parameters = 4,
  DFQueryResult_FieldNumber_AllRequiredParamsPresent = 5,
  DFQueryResult_FieldNumber_FulfillmentText = 6,
  DFQueryResult_FieldNumber_FulfillmentMessagesArray = 7,
  DFQueryResult_FieldNumber_WebhookSource = 8,
  DFQueryResult_FieldNumber_WebhookPayload = 9,
  DFQueryResult_FieldNumber_OutputContextsArray = 10,
  DFQueryResult_FieldNumber_Intent = 11,
  DFQueryResult_FieldNumber_IntentDetectionConfidence = 12,
  DFQueryResult_FieldNumber_DiagnosticInfo = 14,
  DFQueryResult_FieldNumber_LanguageCode = 15,
  DFQueryResult_FieldNumber_SentimentAnalysisResult = 17,
  DFQueryResult_FieldNumber_KnowledgeAnswers = 18,
};

/**
 * Represents the result of conversational query or event processing.
 **/
@interface DFQueryResult : GPBMessage

/**
 * The original conversational query text:
 * - If natural language text was provided as input, `query_text` contains
 *   a copy of the input.
 * - If natural language speech audio was provided as input, `query_text`
 *   contains the speech recognition result. If speech recognizer produced
 *   multiple alternatives, a particular one is picked.
 * - If an event was provided as input, `query_text` is not set.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *queryText;

/**
 * The language that was triggered during intent detection.
 * See [Language Support](https://dialogflow.com/docs/reference/language)
 * for a list of the currently supported language codes.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *languageCode;

/**
 * The Speech recognition confidence between 0.0 and 1.0. A higher number
 * indicates an estimated greater likelihood that the recognized words are
 * correct. The default of 0.0 is a sentinel value indicating that confidence
 * was not set.
 *
 * This field is not guaranteed to be accurate or set. In particular this
 * field isn't set for StreamingDetectIntent since the streaming endpoint has
 * separate confidence estimates per portion of the audio in
 * StreamingRecognitionResult.
 **/
@property(nonatomic, readwrite) float speechRecognitionConfidence;

/** The action name from the matched intent. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *action;

/** The collection of extracted parameters. */
@property(nonatomic, readwrite, strong, null_resettable) GPBStruct *parameters;
/** Test to see if @c parameters has been set. */
@property(nonatomic, readwrite) BOOL hasParameters;

/**
 * This field is set to:
 * - `false` if the matched intent has required parameters and not all of
 *    the required parameter values have been collected.
 * - `true` if all required parameter values have been collected, or if the
 *    matched intent doesn't contain any required parameters.
 **/
@property(nonatomic, readwrite) BOOL allRequiredParamsPresent;

/** The text to be pronounced to the user or shown on the screen. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *fulfillmentText;

/** The collection of rich messages to present to the user. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFIntent_Message*> *fulfillmentMessagesArray;
/** The number of items in @c fulfillmentMessagesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger fulfillmentMessagesArray_Count;

/**
 * If the query was fulfilled by a webhook call, this field is set to the
 * value of the `source` field returned in the webhook response.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *webhookSource;

/**
 * If the query was fulfilled by a webhook call, this field is set to the
 * value of the `payload` field returned in the webhook response.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GPBStruct *webhookPayload;
/** Test to see if @c webhookPayload has been set. */
@property(nonatomic, readwrite) BOOL hasWebhookPayload;

/**
 * The collection of output contexts. If applicable,
 * `output_contexts.parameters` contains entries with name
 * `<parameter name>.original` containing the original parameter values
 * before the query.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFContext*> *outputContextsArray;
/** The number of items in @c outputContextsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger outputContextsArray_Count;

/**
 * The intent that matched the conversational query. Some, not
 * all fields are filled in this message, including but not limited to:
 * `name`, `display_name` and `webhook_state`.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFIntent *intent;
/** Test to see if @c intent has been set. */
@property(nonatomic, readwrite) BOOL hasIntent;

/**
 * The intent detection confidence. Values range from 0.0
 * (completely uncertain) to 1.0 (completely certain).
 * If there are `multiple knowledge_answers` messages, this value is set to
 * the greatest `knowledgeAnswers.match_confidence` value in the list.
 **/
@property(nonatomic, readwrite) float intentDetectionConfidence;

/**
 * The free-form diagnostic info. For example, this field
 * could contain webhook call latency.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GPBStruct *diagnosticInfo;
/** Test to see if @c diagnosticInfo has been set. */
@property(nonatomic, readwrite) BOOL hasDiagnosticInfo;

/**
 * The sentiment analysis result, which depends on the
 * `sentiment_analysis_request_config` specified in the request.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFSentimentAnalysisResult *sentimentAnalysisResult;
/** Test to see if @c sentimentAnalysisResult has been set. */
@property(nonatomic, readwrite) BOOL hasSentimentAnalysisResult;

/**
 * The result from Knowledge Connector (if any), ordered by decreasing
 * `KnowledgeAnswers.match_confidence`.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFKnowledgeAnswers *knowledgeAnswers;
/** Test to see if @c knowledgeAnswers has been set. */
@property(nonatomic, readwrite) BOOL hasKnowledgeAnswers;

@end

#pragma mark - DFKnowledgeAnswers

typedef GPB_ENUM(DFKnowledgeAnswers_FieldNumber) {
  DFKnowledgeAnswers_FieldNumber_AnswersArray = 1,
};

/**
 * Represents the result of querying a Knowledge base.
 **/
@interface DFKnowledgeAnswers : GPBMessage

/** A list of answers from Knowledge Connector. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFKnowledgeAnswers_Answer*> *answersArray;
/** The number of items in @c answersArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger answersArray_Count;

@end

#pragma mark - DFKnowledgeAnswers_Answer

typedef GPB_ENUM(DFKnowledgeAnswers_Answer_FieldNumber) {
  DFKnowledgeAnswers_Answer_FieldNumber_Source = 1,
  DFKnowledgeAnswers_Answer_FieldNumber_FaqQuestion = 2,
  DFKnowledgeAnswers_Answer_FieldNumber_Answer = 3,
  DFKnowledgeAnswers_Answer_FieldNumber_MatchConfidenceLevel = 4,
  DFKnowledgeAnswers_Answer_FieldNumber_MatchConfidence = 5,
};

/**
 * An answer from Knowledge Connector.
 **/
@interface DFKnowledgeAnswers_Answer : GPBMessage

/**
 * Indicates which Knowledge Document this answer was extracted from.
 * Format: `projects/<Project ID>/knowledgeBases/<Knowledge Base
 * ID>/documents/<Document ID>`.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *source;

/**
 * The corresponding FAQ question if the answer was extracted from a FAQ
 * Document, empty otherwise.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *faqQuestion;

/**
 * The piece of text from the `source` knowledge base document that answers
 * this conversational query.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *answer;

/**
 * The system's confidence level that this knowledge answer is a good match
 * for this conversational query.
 * NOTE: The confidence level for a given `<query, answer>` pair may change
 * without notice, as it depends on models that are constantly being
 * improved. However, it will change less frequently than the confidence
 * score below, and should be preferred for referencing the quality of an
 * answer.
 **/
@property(nonatomic, readwrite) DFKnowledgeAnswers_Answer_MatchConfidenceLevel matchConfidenceLevel;

/**
 * The system's confidence score that this Knowledge answer is a good match
 * for this converstational query, range from 0.0 (completely uncertain)
 * to 1.0 (completely certain).
 * Note: The confidence score is likely to vary somewhat (possibly even for
 * identical requests), as the underlying model is under constant
 * improvement, we may deprecate it in the future. We recommend using
 * `match_confidence_level` which should be generally more stable.
 **/
@property(nonatomic, readwrite) float matchConfidence;

@end

/**
 * Fetches the raw value of a @c DFKnowledgeAnswers_Answer's @c matchConfidenceLevel property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t DFKnowledgeAnswers_Answer_MatchConfidenceLevel_RawValue(DFKnowledgeAnswers_Answer *message);
/**
 * Sets the raw value of an @c DFKnowledgeAnswers_Answer's @c matchConfidenceLevel property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetDFKnowledgeAnswers_Answer_MatchConfidenceLevel_RawValue(DFKnowledgeAnswers_Answer *message, int32_t value);

#pragma mark - DFStreamingDetectIntentRequest

typedef GPB_ENUM(DFStreamingDetectIntentRequest_FieldNumber) {
  DFStreamingDetectIntentRequest_FieldNumber_Session = 1,
  DFStreamingDetectIntentRequest_FieldNumber_QueryParams = 2,
  DFStreamingDetectIntentRequest_FieldNumber_QueryInput = 3,
  DFStreamingDetectIntentRequest_FieldNumber_SingleUtterance = 4,
  DFStreamingDetectIntentRequest_FieldNumber_OutputAudioConfig = 5,
  DFStreamingDetectIntentRequest_FieldNumber_InputAudio = 6,
};

/**
 * The top-level message sent by the client to the
 * `StreamingDetectIntent` method.
 *
 * Multiple request messages should be sent in order:
 *
 * 1.  The first message must contain `session`, `query_input` plus optionally
 *     `query_params` and/or `single_utterance`. If the client wants to receive
 *     an audio response, it should also contain `output_audio_config`.
 *     The message must not contain `input_audio`.
 *
 * 2.  If `query_input` was set to a streaming input audio config,
 *     all subsequent messages must contain only `input_audio`.
 *     Otherwise, finish the request stream.
 **/
@interface DFStreamingDetectIntentRequest : GPBMessage

/**
 * Required. The name of the session the query is sent to.
 * Format of the session name:
 * `projects/<Project ID>/agent/sessions/<Session ID>`, or
 * `projects/<Project ID>/agent/environments/<Environment ID>/users/<User
 * ID>/sessions/<Session ID>`. If `Environment ID` is not specified, we assume
 * default 'draft' environment. If `User ID` is not specified, we are using
 * "-". It’s up to the API caller to choose an appropriate `Session ID` and
 * `User Id`. They can be a random numbers or some type of user and session
 * identifiers (preferably hashed). The length of the `Session ID` and
 * `User ID` must not exceed 36 characters.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *session;

/** Optional. The parameters of this query. */
@property(nonatomic, readwrite, strong, null_resettable) DFQueryParameters *queryParams;
/** Test to see if @c queryParams has been set. */
@property(nonatomic, readwrite) BOOL hasQueryParams;

/**
 * Required. The input specification. It can be set to:
 *
 * 1.  an audio config which instructs the speech recognizer how to process
 *     the speech audio,
 *
 * 2.  a conversational query in the form of text, or
 *
 * 3.  an event that specifies which intent to trigger.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFQueryInput *queryInput;
/** Test to see if @c queryInput has been set. */
@property(nonatomic, readwrite) BOOL hasQueryInput;

/**
 * Optional. If `false` (default), recognition does not cease until the
 * client closes the stream.
 * If `true`, the recognizer will detect a single spoken utterance in input
 * audio. Recognition ceases when it detects the audio's voice has
 * stopped or paused. In this case, once a detected intent is received, the
 * client should close the stream and start a new request with a new stream as
 * needed.
 * This setting is ignored when `query_input` is a piece of text or an event.
 **/
@property(nonatomic, readwrite) BOOL singleUtterance;

/**
 * Optional. Instructs the speech synthesizer how to generate the output
 * audio. If this field is not set and agent-level speech synthesizer is not
 * configured, no output audio is generated.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFOutputAudioConfig *outputAudioConfig;
/** Test to see if @c outputAudioConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputAudioConfig;

/**
 * Optional. The input audio content to be recognized. Must be sent if
 * `query_input` was set to a streaming input audio config. The complete audio
 * over all streaming messages must not exceed 1 minute.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSData *inputAudio;

@end

#pragma mark - DFStreamingDetectIntentResponse

typedef GPB_ENUM(DFStreamingDetectIntentResponse_FieldNumber) {
  DFStreamingDetectIntentResponse_FieldNumber_ResponseId = 1,
  DFStreamingDetectIntentResponse_FieldNumber_RecognitionResult = 2,
  DFStreamingDetectIntentResponse_FieldNumber_QueryResult = 3,
  DFStreamingDetectIntentResponse_FieldNumber_WebhookStatus = 4,
  DFStreamingDetectIntentResponse_FieldNumber_OutputAudio = 5,
  DFStreamingDetectIntentResponse_FieldNumber_OutputAudioConfig = 6,
  DFStreamingDetectIntentResponse_FieldNumber_AlternativeQueryResultsArray = 7,
};

/**
 * The top-level message returned from the
 * `StreamingDetectIntent` method.
 *
 * Multiple response messages can be returned in order:
 *
 * 1.  If the input was set to streaming audio, the first one or more messages
 *     contain `recognition_result`. Each `recognition_result` represents a more
 *     complete transcript of what the user said. The last `recognition_result`
 *     has `is_final` set to `true`.
 *
 * 2.  The next message contains `response_id`, `query_result`,
 *     `alternative_query_results` and optionally `webhook_status` if a WebHook
 *     was called.
 *
 * 3.  If `output_audio_config` was specified in the request or agent-level
 *     speech synthesizer is configured, all subsequent messages contain
 *     `output_audio` and `output_audio_config`.
 **/
@interface DFStreamingDetectIntentResponse : GPBMessage

/**
 * The unique identifier of the response. It can be used to
 * locate a response in the training example set or for reporting issues.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *responseId;

/** The result of speech recognition. */
@property(nonatomic, readwrite, strong, null_resettable) DFStreamingRecognitionResult *recognitionResult;
/** Test to see if @c recognitionResult has been set. */
@property(nonatomic, readwrite) BOOL hasRecognitionResult;

/**
 * The selected results of the conversational query or event processing.
 * See `alternative_query_results` for additional potential results.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFQueryResult *queryResult;
/** Test to see if @c queryResult has been set. */
@property(nonatomic, readwrite) BOOL hasQueryResult;

/**
 * If Knowledge Connectors are enabled, there could be more than one result
 * returned for a given query or event and this field will contain all results
 * except for the top one which is captured in query_result. The alternative
 * results are ordered by decreasing
 * `QueryResult.intent_detection_confidence`. If Knowledge Connectors are
 * disabled this field will be empty  at which point those additional results
 * will be surfaced here.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<DFQueryResult*> *alternativeQueryResultsArray;
/** The number of items in @c alternativeQueryResultsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger alternativeQueryResultsArray_Count;

/** Specifies the status of the webhook request. */
@property(nonatomic, readwrite, strong, null_resettable) Status *webhookStatus;
/** Test to see if @c webhookStatus has been set. */
@property(nonatomic, readwrite) BOOL hasWebhookStatus;

/** The audio data bytes encoded as specified in the request. */
@property(nonatomic, readwrite, copy, null_resettable) NSData *outputAudio;

/**
 * Instructs the speech synthesizer how to generate the output audio. This
 * field is populated from the agent-level speech synthesizer configuration,
 * if enabled.
 **/
@property(nonatomic, readwrite, strong, null_resettable) DFOutputAudioConfig *outputAudioConfig;
/** Test to see if @c outputAudioConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputAudioConfig;

@end

#pragma mark - DFStreamingRecognitionResult

typedef GPB_ENUM(DFStreamingRecognitionResult_FieldNumber) {
  DFStreamingRecognitionResult_FieldNumber_MessageType = 1,
  DFStreamingRecognitionResult_FieldNumber_Transcript = 2,
  DFStreamingRecognitionResult_FieldNumber_IsFinal = 3,
  DFStreamingRecognitionResult_FieldNumber_Confidence = 4,
};

/**
 * Contains a speech recognition result corresponding to a portion of the audio
 * that is currently being processed or an indication that this is the end
 * of the single requested utterance.
 *
 * Example:
 *
 * 1.  transcript: "tube"
 *
 * 2.  transcript: "to be a"
 *
 * 3.  transcript: "to be"
 *
 * 4.  transcript: "to be or not to be"
 *     is_final: true
 *
 * 5.  transcript: " that's"
 *
 * 6.  transcript: " that is"
 *
 * 7.  recognition_event_type: `RECOGNITION_EVENT_END_OF_SINGLE_UTTERANCE`
 *
 * 8.  transcript: " that is the question"
 *     is_final: true
 *
 * Only two of the responses contain final results (#4 and #8 indicated by
 * `is_final: true`). Concatenating these generates the full transcript: "to be
 * or not to be that is the question".
 *
 * In each response we populate:
 *
 * *  for `MESSAGE_TYPE_TRANSCRIPT`: `transcript` and possibly `is_final`.
 *
 * *  for `MESSAGE_TYPE_END_OF_SINGLE_UTTERANCE`: only `event_type`.
 **/
@interface DFStreamingRecognitionResult : GPBMessage

/** Type of the result message. */
@property(nonatomic, readwrite) DFStreamingRecognitionResult_MessageType messageType;

/**
 * Transcript text representing the words that the user spoke.
 * Populated if and only if `event_type` = `RECOGNITION_EVENT_TRANSCRIPT`.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *transcript;

/**
 * The default of 0.0 is a sentinel value indicating `confidence` was not set.
 * If `false`, the `StreamingRecognitionResult` represents an
 * interim result that may change. If `true`, the recognizer will not return
 * any further hypotheses about this piece of the audio. May only be populated
 * for `event_type` = `RECOGNITION_EVENT_TRANSCRIPT`.
 **/
@property(nonatomic, readwrite) BOOL isFinal;

/**
 * The Speech confidence between 0.0 and 1.0 for the current portion of audio.
 * A higher number indicates an estimated greater likelihood that the
 * recognized words are correct. The default of 0.0 is a sentinel value
 * indicating that confidence was not set.
 *
 * This field is typically only provided if `is_final` is true and you should
 * not rely on it being accurate or even set.
 **/
@property(nonatomic, readwrite) float confidence;

@end

/**
 * Fetches the raw value of a @c DFStreamingRecognitionResult's @c messageType property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t DFStreamingRecognitionResult_MessageType_RawValue(DFStreamingRecognitionResult *message);
/**
 * Sets the raw value of an @c DFStreamingRecognitionResult's @c messageType property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetDFStreamingRecognitionResult_MessageType_RawValue(DFStreamingRecognitionResult *message, int32_t value);

#pragma mark - DFInputAudioConfig

typedef GPB_ENUM(DFInputAudioConfig_FieldNumber) {
  DFInputAudioConfig_FieldNumber_AudioEncoding = 1,
  DFInputAudioConfig_FieldNumber_SampleRateHertz = 2,
  DFInputAudioConfig_FieldNumber_LanguageCode = 3,
  DFInputAudioConfig_FieldNumber_PhraseHintsArray = 4,
  DFInputAudioConfig_FieldNumber_Model = 7,
};

/**
 * Instructs the speech recognizer how to process the audio content.
 **/
@interface DFInputAudioConfig : GPBMessage

/** Required. Audio encoding of the audio content to process. */
@property(nonatomic, readwrite) DFAudioEncoding audioEncoding;

/**
 * Required. Sample rate (in Hertz) of the audio content sent in the query.
 * Refer to
 * [Cloud Speech API
 * documentation](https://cloud.google.com/speech-to-text/docs/basics) for
 * more details.
 **/
@property(nonatomic, readwrite) int32_t sampleRateHertz;

/**
 * Required. The language of the supplied audio. Dialogflow does not do
 * translations. See [Language
 * Support](https://dialogflow.com/docs/languages) for a list of the
 * currently supported language codes. Note that queries in the same session
 * do not necessarily need to specify the same language.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *languageCode;

/**
 * Optional. The collection of phrase hints which are used to boost accuracy
 * of speech recognition.
 * Refer to
 * [Cloud Speech API
 * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
 * for more details.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<NSString*> *phraseHintsArray;
/** The number of items in @c phraseHintsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger phraseHintsArray_Count;

/**
 * Optional. Which Speech model to select for the given request. Select the
 * model best suited to your domain to get best results. If a model is not
 * explicitly specified, then we auto-select a model based on the parameters
 * in the InputAudioConfig.
 * If enhanced speech model is enabled for the agent and an enhanced
 * version of the specified model for the language does not exist, then the
 * speech is recognized using the standard version of the specified model.
 * Refer to
 * [Cloud Speech API
 * documentation](https://cloud.google.com/speech-to-text/docs/basics#select-model)
 * for more details.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *model;

@end

/**
 * Fetches the raw value of a @c DFInputAudioConfig's @c audioEncoding property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t DFInputAudioConfig_AudioEncoding_RawValue(DFInputAudioConfig *message);
/**
 * Sets the raw value of an @c DFInputAudioConfig's @c audioEncoding property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetDFInputAudioConfig_AudioEncoding_RawValue(DFInputAudioConfig *message, int32_t value);

#pragma mark - DFTextInput

typedef GPB_ENUM(DFTextInput_FieldNumber) {
  DFTextInput_FieldNumber_Text = 1,
  DFTextInput_FieldNumber_LanguageCode = 2,
};

/**
 * Represents the natural language text to be processed.
 **/
@interface DFTextInput : GPBMessage

/**
 * Required. The UTF-8 encoded natural language text to be processed.
 * Text length must not exceed 256 bytes.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *text;

/**
 * Required. The language of this conversational query. See [Language
 * Support](https://dialogflow.com/docs/languages) for a list of the
 * currently supported language codes. Note that queries in the same session
 * do not necessarily need to specify the same language.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *languageCode;

@end

#pragma mark - DFEventInput

typedef GPB_ENUM(DFEventInput_FieldNumber) {
  DFEventInput_FieldNumber_Name = 1,
  DFEventInput_FieldNumber_Parameters = 2,
  DFEventInput_FieldNumber_LanguageCode = 3,
};

/**
 * Events allow for matching intents by event name instead of the natural
 * language input. For instance, input `<event: { name: “welcome_event”,
 * parameters: { name: “Sam” } }>` can trigger a personalized welcome response.
 * The parameter `name` may be used by the agent in the response:
 * `“Hello #welcome_event.name! What can I do for you today?”`.
 **/
@interface DFEventInput : GPBMessage

/** Required. The unique identifier of the event. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *name;

/** Optional. The collection of parameters associated with the event. */
@property(nonatomic, readwrite, strong, null_resettable) GPBStruct *parameters;
/** Test to see if @c parameters has been set. */
@property(nonatomic, readwrite) BOOL hasParameters;

/**
 * Required. The language of this query. See [Language
 * Support](https://dialogflow.com/docs/languages) for a list of the
 * currently supported language codes. Note that queries in the same session
 * do not necessarily need to specify the same language.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *languageCode;

@end

#pragma mark - DFSentimentAnalysisRequestConfig

typedef GPB_ENUM(DFSentimentAnalysisRequestConfig_FieldNumber) {
  DFSentimentAnalysisRequestConfig_FieldNumber_AnalyzeQueryTextSentiment = 1,
};

/**
 * Configures the types of sentiment analysis to perform.
 **/
@interface DFSentimentAnalysisRequestConfig : GPBMessage

/**
 * Optional. Instructs the service to perform sentiment analysis on
 * `query_text`. If not provided, sentiment analysis is not performed on
 * `query_text`.
 **/
@property(nonatomic, readwrite) BOOL analyzeQueryTextSentiment;

@end

#pragma mark - DFSentimentAnalysisResult

typedef GPB_ENUM(DFSentimentAnalysisResult_FieldNumber) {
  DFSentimentAnalysisResult_FieldNumber_QueryTextSentiment = 1,
};

/**
 * The result of sentiment analysis as configured by
 * `sentiment_analysis_request_config`.
 **/
@interface DFSentimentAnalysisResult : GPBMessage

/** The sentiment analysis result for `query_text`. */
@property(nonatomic, readwrite, strong, null_resettable) DFSentiment *queryTextSentiment;
/** Test to see if @c queryTextSentiment has been set. */
@property(nonatomic, readwrite) BOOL hasQueryTextSentiment;

@end

#pragma mark - DFSentiment

typedef GPB_ENUM(DFSentiment_FieldNumber) {
  DFSentiment_FieldNumber_Score = 1,
  DFSentiment_FieldNumber_Magnitude = 2,
};

/**
 * The sentiment, such as positive/negative feeling or association, for a unit
 * of analysis, such as the query text.
 **/
@interface DFSentiment : GPBMessage

/**
 * Sentiment score between -1.0 (negative sentiment) and 1.0 (positive
 * sentiment).
 **/
@property(nonatomic, readwrite) float score;

/**
 * A non-negative number in the [0, +inf) range, which represents the absolute
 * magnitude of sentiment, regardless of score (positive or negative).
 **/
@property(nonatomic, readwrite) float magnitude;

@end

NS_ASSUME_NONNULL_END

CF_EXTERN_C_END

#pragma clang diagnostic pop

// @@protoc_insertion_point(global_scope)
